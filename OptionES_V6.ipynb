{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Option Event Study**\n",
    "Code Written by: `Aman Agrawal` <br>\n",
    "Email: aagrawal2@babson.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import log as ln\n",
    "from numpy import NaN as nan\n",
    "from statsmodels.formula.api import ols\n",
    "import os\n",
    "import glob\n",
    "from numpy import sqrt\n",
    "pd.options.mode.chained_assignment = None\n",
    "source = os.path.abspath(os.getcwd())                                           #Getting folder directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketdata = pd.read_excel(\"MktData_MLM.xlsx\")                                  #Importing market log returns data\n",
    "marketdata = marketdata.rename(columns={\"date\":\"DataDate\"})                     #Renaming date column for consistency\n",
    "marketdata = marketdata[marketdata.DataDate.isin(pd.date_range(start = \"2012-12-30\",end=\"2017-12-31\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blr = pd.read_excel(\"BB BLR Index.xlsx\", skiprows = 5)\\\n",
    "    .drop(columns = [\"Date\",\"PX_LAST.1\",\"PX_LAST\",\n",
    "        \"Unnamed: 2\"]).rename(columns={\"Date.1\":\n",
    "            \"DataDate\",\"rate\":\"blr\"})                                           #Importing bank loan rate data from an excel\n",
    "fred = pd.read_excel(\"DGS1 1Yr Constant Mat Treasury.xlsx\",skiprows=10)\\\n",
    "    .rename(columns={\"observation_date\":\"DataDate\",\"DGS1\":\"fred\"})              #Importing fred rate data from an excel\n",
    "fred.fred = fred.fred/100                                                       #Formatting the fred data for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Stock Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_filter = False\n",
    "oi_filter = False\n",
    "zero_price_filter = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These filters are used to create the synthetic stock price. In order to use them, set their value as `True`.\n",
    "| Filter | Description|\n",
    "|---------|-----------|\n",
    "|`volume_filter`     | Removes zero volume contracts from the database |\n",
    "|`oi_filter`         | Removes zero open interest contracts from the database |\n",
    "|`zero_price_filter` | Removes contracts with zero price value. This happens when exchange provides no data for a specific contract | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(df, dtype):\n",
    "    data_type = dtype + \"LogRet\"                                                #Adding a suffix to signify Log Returns \n",
    "    formula = data_type + \" ~  Mkt_Lnrtn\"                                       #Creating the formula for Regression\n",
    "    years = df.index.year.unique().tolist()                                     #Creating a list of years for yearly regression\n",
    "\n",
    "    if 2012 in years:\n",
    "        years.remove(2012)\n",
    "\n",
    "    df_reg = pd.DataFrame()                                                     #Empty df to concat yearly data to \n",
    "\n",
    "    for y in years:                                                             #Running a for loop for yearly regressions\n",
    "        df_year = df.loc[f\"{y}\"]                                                #Filtering for a specific year\n",
    "        if len(df_year) <= 1:\n",
    "            continue\n",
    "        fitted = ols(formula, data = df_year).fit()                             #Running the regression on the filtered year  \n",
    "        expected = fitted.predict(exog = df_year)                               #Calculating the expected returns \n",
    "        df_year.loc[:,\"ExpectedReturn\"] = expected                              #Assigned a column to the expected returns \n",
    "        df_year.loc[:,\"ResRtn\"] = df_year[data_type] - expected                 #Calculating Residual Returns\n",
    "        df_year.loc[:,\"Tstat\"] = df_year.ResRtn/sqrt(fitted.scale)              #Calculating Tstat\n",
    "        df_year.loc[:,\"Sig\"] = abs(df_year.Tstat) > 1.96                        #Checking significance\n",
    "        df_reg = pd.concat([df_reg,df_year])                                    #Joining the yearly regressions  \n",
    "    return(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Stock Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_stock(com_df):\n",
    "    com_df.PRC = abs(com_df.PRC)                                             #DECISION PENDING\n",
    "    com_df = com_df.assign(CompanyLogRet=lambda x: \\\n",
    "        ln((x.PRC*(x.CFACPR.shift(1)/x.CFACPR))/x.PRC.shift(1)))                #Calculating Split Adjusted Log-returns\n",
    "    com_df = com_df[['CompanyLogRet','DataDate']]                               #Getting rid of extra data\n",
    "    com_df.DataDate = pd.to_datetime(com_df.DataDate) \n",
    "    com_df = com_df.merge(marketdata,on='DataDate',how=\"left\")\\\n",
    "        .rename(columns= {'vwretd_ln':'Mkt_Lnrtn'})                             #Joining common stock returns with market returns\n",
    "    com_df[\"DataDate\"] = pd.to_datetime(com_df[\"DataDate\"])                     #Converting dates from str to datetime\n",
    "    com_df = com_df.set_index(\"DataDate\").dropna()                              #Making DataDate as an index column\n",
    "\n",
    "    com_df_reg = regression(com_df,dtype = \"Company\")                           #Running yearly regressions\n",
    "    return(com_df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syn Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_stock(syn_df):\n",
    "    \n",
    "    if volume_filter == True:   \n",
    "        syn_df = syn_df[syn_df.Volume != 0]                                     #Filtering for volume if volume_filter is True\n",
    "    \n",
    "    if oi_filter == True:\n",
    "        syn_df = syn_df[syn_df.OpenInterest != 0]                               #Filtering for open interest if oi_filter is True\n",
    "\n",
    "    syn_df.DataDate = pd.to_datetime(syn_df.DataDate)                           #Converting dates from str to datetime\n",
    "    syn_df.Expiration = pd.to_datetime(syn_df.Expiration)                       #Converting dates from str to datetime\n",
    "\n",
    "    syn_df = syn_df.merge(fred, on = 'DataDate', how = \"left\")                  #Joining fred data with df\n",
    "    syn_df = syn_df.merge(blr, on = 'DataDate', how = \"left\")                   #Joining blr data with df\n",
    "    \n",
    "    syn_df.loc[:,\"Tau\"] = (syn_df.Expiration - syn_df.DataDate).dt.days         #Calculating Tau\n",
    "    syn_df.loc[:,\"YearFrac\"] =  syn_df.Tau/365                                  #Converting Tau into years\n",
    "    syn_df.loc[:,\"fred_nan\"] = syn_df.fred/syn_df.fred                          #Returns a NAN value if fred has a missing data. Will be used to calculate Buy Discount.\n",
    "\n",
    "    syn_df.loc[:,\"BuyDiscount\"] = ((1 + syn_df.fred) ** syn_df.YearFrac)*\\\n",
    "        syn_df.fred_nan                                                         #Calculating Buy Discount. (Without fred_nan, Tau with a value of \"0\" would result into buy discount of \"1\". Currently it would result into a NaN value.)\n",
    "    syn_df.loc[:,\"SellDiscount\"] = (1 + syn_df.blr) ** syn_df.YearFrac          #Calculating Sell Discount\n",
    "    \n",
    "    call = syn_df[syn_df.Type == \"call\"].drop(columns = \"Type\")                 #Splitting the df into calls and puts\n",
    "    call = call.rename(columns={'Last':'CallLast', 'Bid': \"CallBid\",\\\n",
    "        'Ask':\"CallAsk\", 'Volume':\"CallVolume\", 'OpenInterest':\\\n",
    "            'CallOpenInterest', 'IV':\"CallIV\", 'Delta':'CallDelta',\\\n",
    "                'Gamma':'CallGamma', 'Theta':'CallTheta', 'Vega':'CallVega'})   #Renaming the columns\n",
    "    \n",
    "    put = syn_df[syn_df.Type == \"put\"].drop(columns = \"Type\")                   #Splitting the df into calls and puts\n",
    "    put = put.rename(columns={'Last':'PutLast', 'Bid': \"PutBid\", \\\n",
    "        'Ask':\"PutAsk\", 'Volume':\"PutVolume\", 'OpenInterest':\\\n",
    "            'PutOpenInterest', 'IV':\"PutIV\", 'Delta':'PutDelta',\\\n",
    "                'Gamma':'PutGamma', 'Theta':'PutTheta', 'Vega':'PutVega'})      #Renaming the columns\n",
    "    \n",
    "    syn_df = call.merge(put,how = \"left\", on=[\"Expiration\",\"DataDate\",\\\n",
    "        \"Strike\", \"UnderlyingSymbol\",\"UnderlyingPrice\",\"BuyDiscount\",\\\n",
    "            \"SellDiscount\",\"YearFrac\",\"Tau\",\"blr\",\"fred\",\"fred_nan\"])           #Merging the call and put df to make them parallel\n",
    "\n",
    "    if zero_price_filter == True:                                               #Filtering for zero price quotes if zero_price_filter is True \n",
    "        syn_df = syn_df[syn_df[\"CallBid\"] != 0]\n",
    "        syn_df = syn_df[syn_df[\"PutBid\"] != 0]\n",
    "        syn_df = syn_df[syn_df[\"CallAsk\"] != 0]\n",
    "        syn_df = syn_df[syn_df[\"PutAsk\"] != 0]\n",
    "\n",
    "    syn_df = syn_df[syn_df[\"CallBid\"] != 9999]\n",
    "    syn_df = syn_df[syn_df[\"PutBid\"] != 9999]\n",
    "    syn_df = syn_df[syn_df[\"CallAsk\"] != 9999]\n",
    "    syn_df = syn_df[syn_df[\"PutAsk\"] != 9999]\n",
    "\n",
    "    syn_df.loc[:,\"Buy\"] = syn_df.Strike/syn_df.BuyDiscount                      #Calculating Buy price for the bond\n",
    "    \n",
    "    syn_df.loc[:,\"Sell\"] = syn_df.Strike/syn_df.SellDiscount                    #Calculating Sell price for the bond\n",
    "    \n",
    "    syn_df.loc[:,\"SynthAsk\"] = syn_df.CallAsk - \\\n",
    "        syn_df.PutBid + syn_df.Buy                                              #Calculating Synthetic stock's ask price\n",
    "    \n",
    "    syn_df.loc[:,\"SynthBid\"] = syn_df.CallBid - \\\n",
    "        syn_df.PutAsk + syn_df.Sell                                             #Calculating Synthetic stock's sell price\n",
    "    \n",
    "    syn_df.loc[:,\"SynthPrice\"] = (syn_df.SynthAsk + syn_df.SynthBid)/2          #Calculating Synthetic stock's price for the specific strike price on a day\n",
    "\n",
    "    syn_df = syn_df.groupby(\"DataDate\").mean()                                  #Calculating Synthetic stock's price on a day\n",
    "    \n",
    "    syn_df = marketdata.merge(syn_df,on='DataDate',how = \"left\")\\\n",
    "        .rename(columns= {'vwretd_ln':'Mkt_Lnrtn'})                             #Joining Synthetic stock returns with market returns\n",
    "    \n",
    "    syn_df.loc[:,\"SynthLogRet\"] = \\\n",
    "        ln((syn_df.SynthPrice/syn_df.SynthPrice.shift(1)))                      #Calculating Synthetic Stock's Log returns\n",
    "\n",
    "    syn_df = syn_df[['DataDate',\"SynthLogRet\",'Mkt_Lnrtn',\"SynthPrice\"]]\\\n",
    "        .set_index(\"DataDate\").dropna(subset=\"SynthLogRet\")                     #Dropping the NA values based upon Synth Log returns \n",
    "\n",
    "    syn_df_reg = regression(syn_df,dtype = \"Synth\")                             #Running yearly regressions \n",
    "    \n",
    "    return(syn_df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivol_paths = glob.glob(f\"{source}\\\\ind_1\\\\*_ind.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in ivol_paths:\n",
    "    tic = i.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "    print(tic)\n",
    "    \n",
    "    try:\n",
    "        com_path = glob.glob(f\"{source}/crsp_ind/{tic}*_ind.csv\")[0]\n",
    "    except:\n",
    "        error.append(f\"{tic} : No crsp data\")\n",
    "        continue\n",
    "\n",
    "    ivol = pd.read_csv(i).drop(columns=\"Unnamed: 0\")                                        #Importing option data\n",
    "    com_return = pd.read_csv(com_path).drop(columns=\"Unnamed: 0\") #Importing common stock daily data\n",
    "\n",
    "    com_return=com_return.rename(columns = {'date':'DataDate'})                     #Renaming date column for consistency\n",
    "    \n",
    "    common_regression = common_stock(com_return).reset_index()                         #Cleaning common stock data and returning regression\n",
    "    synthetic_regression = synthetic_stock(ivol).reset_index()                   #Cleaning synthetic stock data and returning regression\n",
    "    \n",
    "    if len(synthetic_regression) == 0:\n",
    "        error.append(f\"{tic} : Insufficient Syn Data.\")\n",
    "        continue\n",
    "    \n",
    "    synthetic_regression = synthetic_regression\\\n",
    "        [[\"DataDate\",\"ResRtn\",\"Tstat\",\"Sig\"]]                                   #Filtering for required data\n",
    "    \n",
    "    common_regression = common_regression[[\"DataDate\",\"ResRtn\",\"Tstat\",\"Sig\"]]  #Filtering for required data\n",
    "    \n",
    "    synthetic_regression = synthetic_regression.rename(columns=\\\n",
    "        {\"ResRtn\":\"SynResRtn\",\"Tstat\":\"SynTstat\",\"Sig\":\"SynSig\"})               #Renaming columns for joining the dfs\n",
    "    \n",
    "    common_regression = common_regression.rename(columns=\\\n",
    "        {\"ResRtn\":\"ComResRtn\",\"Tstat\":\"ComTstat\",\"Sig\":\"ComSig\"})               #Renaming columns for joining the dfs\n",
    "    \n",
    "    summary = synthetic_regression.merge(common_regression,\\\n",
    "        on=\"DataDate\",how = \"right\")                                                          #Joining the common and synthetic regression df based on \"DataDate\"(index)\n",
    "    \n",
    "    summary.loc[:,\"Equal\"] = summary.SynSig == summary.ComSig                   #Checking if both, syn and common, Tstats are significant\n",
    "    summary.loc[:,\"Direction\"] = (summary.SynTstat/summary.ComTstat) >= 0       #Checking if the direction of both Tstats are similar\n",
    "    \n",
    "    for i in summary.index:                                                     #Checking for Redflags\n",
    "        \n",
    "        if summary.loc[i,\"Equal\"] == False:                                     #Redflag = True, if significance is not equal \n",
    "            summary.loc[i,\"Redflag\"] = True\n",
    "        \n",
    "        elif summary.loc[i,\"Equal\"] == True and (summary.loc[i,\"SynSig\"]\\\n",
    "            == False or summary.loc[i,\"ComSig\"] == False):                      #Redflag = False, if significance is equal but both are not significant\n",
    "            summary.loc[i,\"Redflag\"] = False\n",
    "        \n",
    "        elif summary.loc[i,\"Equal\"] == True and \\\n",
    "            summary.loc[i,\"Direction\"] == False:                                #Redflag = True, if significance is equal (both significant) but are in opposite directions\n",
    "            summary.loc[i,\"Redflag\"] = True\n",
    "        \n",
    "        else:                                                                   #Redflag = False, if significance is equal and the direction is same\n",
    "            summary.loc[i,\"Redflag\"] = False\n",
    "    \n",
    "    print(tic,\"Done\",summary.__len__())\n",
    "    \n",
    "    summary_path = f'{source}/summary'                                          #File path for export of summary\n",
    "    if not os.path.exists(summary_path):                                        #Creating the folder summary if it doesn't exist in the filepath\n",
    "        os.makedirs(f\"{source}/summary\")\n",
    "    \n",
    "    summary.to_csv(f\"{source}/summary/{tic}_summary.csv\")                       #Exporting a csv file for the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_tic = []\n",
    "error_reason = []\n",
    "\n",
    "for i in error:\n",
    "    error_tic.append(i.split(\":\")[0].strip())\n",
    "    error_reason.append(i.split(\":\")[1].strip())\n",
    "\n",
    "error_df = pd.DataFrame({\"tic\":error_tic,\"reason\":error_reason},index=range(1,1+len(error)))\n",
    "error_df.to_csv(\"error.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df = pd.read_csv(f\"{source}\\\\ind_1\\\\ACUR_ind.csv\").drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "if volume_filter == True:   \n",
    "    syn_df = syn_df[syn_df.Volume != 0]                                     #Filtering for volume if volume_filter is True\n",
    "\n",
    "if oi_filter == True:\n",
    "    syn_df = syn_df[syn_df.OpenInterest != 0]                               #Filtering for open interest if oi_filter is True\n",
    "\n",
    "syn_df.DataDate = pd.to_datetime(syn_df.DataDate)                           #Converting dates from str to datetime\n",
    "syn_df.Expiration = pd.to_datetime(syn_df.Expiration)                       #Converting dates from str to datetime\n",
    "\n",
    "syn_df = syn_df.merge(fred, on = 'DataDate', how = \"left\")                  #Joining fred data with df\n",
    "syn_df = syn_df.merge(blr, on = 'DataDate', how = \"left\")                   #Joining blr data with df\n",
    "\n",
    "syn_df.loc[:,\"Tau\"] = (syn_df.Expiration - syn_df.DataDate).dt.days         #Calculating Tau\n",
    "syn_df.loc[:,\"YearFrac\"] =  syn_df.Tau/365                                  #Converting Tau into years\n",
    "syn_df.loc[:,\"fred_nan\"] = syn_df.fred/syn_df.fred                          #Returns a NAN value if fred has a missing data. Will be used to calculate Buy Discount.\n",
    "\n",
    "syn_df.loc[:,\"BuyDiscount\"] = ((1 + syn_df.fred) ** syn_df.YearFrac)*\\\n",
    "    syn_df.fred_nan                                                         #Calculating Buy Discount. (Without fred_nan, Tau with a value of \"0\" would result into buy discount of \"1\". Currently it would result into a NaN value.)\n",
    "syn_df.loc[:,\"SellDiscount\"] = (1 + syn_df.blr) ** syn_df.YearFrac          #Calculating Sell Discount\n",
    "\n",
    "call = syn_df[syn_df.Type == \"call\"].drop(columns = \"Type\")                 #Splitting the df into calls and puts\n",
    "call = call.rename(columns={'Last':'CallLast', 'Bid': \"CallBid\",\\\n",
    "    'Ask':\"CallAsk\", 'Volume':\"CallVolume\", 'OpenInterest':\\\n",
    "        'CallOpenInterest', 'IV':\"CallIV\", 'Delta':'CallDelta',\\\n",
    "            'Gamma':'CallGamma', 'Theta':'CallTheta', 'Vega':'CallVega'})   #Renaming the columns\n",
    "\n",
    "put = syn_df[syn_df.Type == \"put\"].drop(columns = \"Type\")                   #Splitting the df into calls and puts\n",
    "put = put.rename(columns={'Last':'PutLast', 'Bid': \"PutBid\", \\\n",
    "    'Ask':\"PutAsk\", 'Volume':\"PutVolume\", 'OpenInterest':\\\n",
    "        'PutOpenInterest', 'IV':\"PutIV\", 'Delta':'PutDelta',\\\n",
    "            'Gamma':'PutGamma', 'Theta':'PutTheta', 'Vega':'PutVega'})      #Renaming the columns\n",
    "\n",
    "syn_df = call.merge(put,how = \"left\", on=[\"Expiration\",\"DataDate\",\\\n",
    "    \"Strike\", \"UnderlyingSymbol\",\"UnderlyingPrice\",\"BuyDiscount\",\\\n",
    "        \"SellDiscount\",\"YearFrac\",\"Tau\",\"blr\",\"fred\",\"fred_nan\"])           #Merging the call and put df to make them parallel\n",
    "\n",
    "if zero_price_filter == True:                                               #Filtering for zero price quotes if zero_price_filter is True \n",
    "    syn_df = syn_df[syn_df[\"CallBid\"] != 0]\n",
    "    syn_df = syn_df[syn_df[\"PutBid\"] != 0]\n",
    "    syn_df = syn_df[syn_df[\"CallAsk\"] != 0]\n",
    "    syn_df = syn_df[syn_df[\"PutAsk\"] != 0]\n",
    "\n",
    "syn_df = syn_df[syn_df[\"CallBid\"] != 9999]\n",
    "syn_df = syn_df[syn_df[\"PutBid\"] != 9999]\n",
    "syn_df = syn_df[syn_df[\"CallAsk\"] != 9999]\n",
    "syn_df = syn_df[syn_df[\"PutAsk\"] != 9999]\n",
    "\n",
    "syn_df.loc[:,\"Buy\"] = syn_df.Strike/syn_df.BuyDiscount                      #Calculating Buy price for the bond\n",
    "\n",
    "syn_df.loc[:,\"Sell\"] = syn_df.Strike/syn_df.SellDiscount                    #Calculating Sell price for the bond\n",
    "\n",
    "syn_df.loc[:,\"SynthAsk\"] = syn_df.CallAsk - \\\n",
    "    syn_df.PutBid + syn_df.Buy                                              #Calculating Synthetic stock's ask price\n",
    "\n",
    "syn_df.loc[:,\"SynthBid\"] = syn_df.CallBid - \\\n",
    "    syn_df.PutAsk + syn_df.Sell                                             #Calculating Synthetic stock's sell price\n",
    "\n",
    "syn_df.loc[:,\"SynthPrice\"] = (syn_df.SynthAsk + syn_df.SynthBid)/2          #Calculating Synthetic stock's price for the specific strike price on a day\n",
    "\n",
    "syn_df = syn_df.groupby(\"DataDate\").mean()                                  #Calculating Synthetic stock's price on a day\n",
    "\n",
    "syn_df = marketdata.merge(syn_df,on='DataDate',how = \"left\")\\\n",
    "    .rename(columns= {'vwretd_ln':'Mkt_Lnrtn'})                             #Joining Synthetic stock returns with market returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df[syn_df.SynthPrice < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "syn_df.loc[:,\"SynthLogRet\"] = \\\n",
    "    ln((syn_df.SynthPrice/syn_df.SynthPrice.shift(1)))                      #Calculating Synthetic Stock's Log returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "syn_df = syn_df[['DataDate',\"SynthLogRet\",'Mkt_Lnrtn',\"SynthPrice\"]]\\\n",
    "    .set_index(\"DataDate\").dropna(subset=\"SynthLogRet\")                     #Dropping the NA values based upon Synth Log returns \n",
    "\n",
    "syn_df_reg = regression(syn_df,dtype = \"Synth\")                             #Running yearly regressions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6453629d7211d10f948ea67968a257c26208e64e999b29db1f6a7389fca678f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
